#TIL #스파르타코딩클럽 [[TIL]]

## 앙상블 학습
### 1. 앙상블 학습
- 여러 개의 머신러닝 모델을 결합하여 예측 성능을 향상시키는 기법
- 하나의 모델이 예측할 때 발생할 수 있는 오차를 줄이고 더 안정적이고 정확한 결과를 얻을 수 있음


### 2. 앙상블 학습방법의 종류
1) 배깅(Bagging)
	- 여러 개의 모델을 병렬적으로 학습하고, 각 모델의 결과를 평균 내거나 다수결로 결정
	- 모델의 분산을 줄여주기 때문에, 단일 모델보다 더 나은 성능을 보일 수 있음
2) 부스팅(Boosting)
	- 모델을 순차적으로 학습하면서, 이전 모델이 틀린 부분에 더 가중치를 두어 학습하는 방법
3) 스태킹(Stacking)
	- 개별 모델들이 예측한 결과를 입력으로 하는 또 다른 모델을 만들어 최종 예측을 수행


### 3. 앙상블 학습의 장점
- 다양한 모델의 예측을 결합함으로써 하나의 모델보다 더 강력하고 안정적인 예측 성능을 얻을 수 있음
- 데이터에 노이즈가 있거나 모델이 오버피팅될 가능성이 있는 경우에 유용



## fit_transform vs transform
### 1. fit_transform
- 역할: 주어진 데이터를 학습하고, 학습한 내용을 바탕으로 데이터를 변환
- 작동 방식: 먼저 데이터를 사용하여 내부적으로 필요한 계산을 수행하여 학습한 뒤, 그 데이터를 변환
- 사용 시기: 학습 데이터를 처음으로 전처리할 때 사용


모델 평가치

베이즈 정리
