#fullstack #gpt #Nomad_Coder [[Nomad Coder]]

## 3.0 LLMs and Chat Models
### 1. LangChain
- 다양한 언어 모델(LLM)을 통합하고 활용할 수 있도록 해주는 오픈소스 프레임워크
- 여러 AI 언어 모델 API와의 통합을 쉽게 해주고, 체인을 구성하도록 도와줌


### 2. LangChain의 주요 기능
- 모델 연결 및 관리: 다양한 언어 모델(GPT-3, GPT-4 등)을 쉽게 연결하고 사용 가능하게 함
- 체인 구성: 여러 단계를 거쳐 실행할 수 있는 체인을 구성
	- 예: '질문 분석 -> 관련 정보 검색 -> 요약 -> 답변 생성'과 같은 일련의 작업을 한 번에 처리
- 프롬프트 관리: 프롬프트를 쉽게 생성하고, 템플릿으로 관리할 수 있게 도와줌
	- 프롬프트(prompt): 언어 모델에 입력되는 텍스트
- 도구 통합: 데이터베이스 검색, API 호출, 웹 스크래핑 등 외부 도구와 언어 모델을 결합하여 더욱 복잡한 애플리케이션을 제작하는데 도움을 줌


### 3. LangChain의 구성 요소
- LLM(Large Language Model): OpenAI와 같은 언어 모델을 사용할 수 있게 연결하는 인터페이스
- 체인(Chains): 여러 단계를 거쳐 작업을 수행하는 프로세스
- 에이전트(Agents): 체인과 도구들을 결합하여, 다양한 정보를 수집하고 처리하는 일련의 작업을 수행하는 기능
- 프롬프트 템플릿(Prompt Templates): 언어 모델에 전달할 프롬프트를 쉽게 구성하고 관리할 수 있는 방법


### 4. LangChain을 사용하는 이유
- 유연성: 다양한 언어 모델과 통합할 수 있고, 필요에 따라 다른 도구나 API와 연결할 수 있어 매우 유연하게 AI 애플리케이션을 개발할 수 있음
- 효율성: LangChain은 반복적이고 유사한 작업을 자동화하여, 일관성 있고 효율적인 응답을 제공


### 5. LangChain 사용 예시
```python
from langchain.chat_models import ChatOpenAI

chat = ChatOpenAI()

b = chat.predict('How many planets are there?')

print(b)
# 'There are eight planets in our solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.'
```



## 3.1 Predict Messages
### 1. ChatOpenAI
- OpanAI의 chat model(GPT-3.5 또는 GPT-4 등)을 활용하여 대화형 AI 애플리케이션을 구축할 때 사용되는 인터페이스
- LangChain 프레임워크 내에서 OpenAI의 chat model을 쉽고 유연하게 활용할 수 있도록 도와주는 중요한 컴포넌트
- 대화형 AI 애플리케이션을 빠르고 효율적으로 개발 가능

### 2. ChatOpenAI의 기능과 특징
1) 대화형 AI 인터페이스
	- `ChatOpenAI`는 OpenAI의 chat model을 사용하여 대화형 인터페이스를 제공
	- API 호출을 통해 챗봇이나 대화형 애플리케이션을 쉽게 구축 가능
2) 속성 및 설정
	- model_name: `ChatOpenAI`는 GPT-3.5 또는 GPT-4 같은 다양한 모델을 선택 가능
	- 온도(temperature): 생성되는 응답의 창의성 정도를 설정하는 파라미터
		- 0 ~ 2 까지의 범위를 가짐.
		- 결정적이고 예측 가능 (0) <-> 창의적이고 예측 하기 어려움 (2)
		- 일반적으로 0.7 정도가 균형 잡힌 값을 제공하나 때에 따라 조절 가능
	- max_tokens: 한 번의 응답에서 생성할 최대 토큰 수를 설정하여 모델의 출력 길이를 제어
3) 사용 용이성
	- 간편한 API 호출 방식을 제공하여, 사용자가 복잡한 설정 없이 쉽게 대화형 모델 사용 가능
	- 대화의 문맥을 유지하며 연속적인 메시지 처리가 가능하도록 설계되어 있어, 대화형 애플리케이션 개발에 적합
4) 추상화와 확장성
	- LangChain은 `ChatOpenAI`를 통해 대화형 모델과의 상호작용을 추상화하여, 사용자가 직접 OpenAI API를 호출하는 것보다 더 간단하고 직관적인 코드를 작성 가능
	- API 버전이나 모델 변경 시에도 코드 수정이 최소화되도록 설계됨

### 3. HumanMessage, AIMessage, SystemMessage
- LangChain에서 대화형 애플리케이션을 구축할 때 사용하는 메시지 타입들 중 일부
- 각각의 메시지가 어떤 역할을 하는지 명확하게 정의해주며, 챗봇의 대화 흐름 관리에 사용

1) HumanMessage
	- 사용자가 챗봇에게 보내는 메시지
	- 사용자의 입력, 질문, 명령 등을 표현하며, AI가 이 메시지를 바탕으로 응답을 생성
2) AIMessage
	- AI가 사용자에게 보내는 응답 메시지
	- `HumanMessage`에 대한 AI의 답변으로, 챗봇이 생성하는 텍스트가 포함됨
3) SystemMessage
	- 대화의 맥락이나 AI의 행동 방침을 설정하기 위해 사용되는 메시지
	- AI가 어떻게 응답해야 하는지 지시하거나, 대화의 초기 설정을 제공하는 데 사용

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, AIMessage, SystemMessage

chat = ChatOpenAI(temperature=0.1)

# 가상의 대화 설정
messages = [
    SystemMessage(
        content="You are a geography expert. And you only reply in Korean."
    ),
    AIMessage(content="안녕! 나는 챗봇이야."),
    HumanMessage(content="What is the distance between Korea and Japan? Also, what is your name?"),
]

chat.predict_messages(messages)

# 출력
AIMessage(content='한국과 일본 사이의 거리는 약 900km입니다. 제 이름은 챗봇이에요.')
```



## 3.2 Prompt Templates
### 1. 왜 prompt가 중요한가?
1) AI의 행동과 역할 설정
2) 대화의 맥락과 목적 제공
3) 출력의 창의성과 일관성 조절
4) 사용자 경험(UX) 향상
5) 문제 해결과 성능 최적화


### 2. PromptTemplate, ChatPromptTemplate
1) PromptTemplate
	- 정적 프롬프트 템플릿을 정의할 때 사용
	- 변수와 placeholder를 포함한 텍스트 기반 prompt를 생성할 수 있으며, 실행 시점에 구체적인 값을 대입하여 완성된 prompt 제작
	- 주로 단순한 질문이나 명령 생성에 유용

2) ChatPromptTemplate
	- 대화형 프롬프트 템플릿으로, `HumanMessage`, `AIMessage`, `SystemMessage` 등 여러 메시지 타입을 조합하여 대화의 구조를 설계할 때 사용
	- 대화의 각 단계마다 다른 메시지 타입을 지정하고, 이를 통해 AI와 사용자의 대화 흐름을 관리하며 여러 맥락에 맞는 응답을 유도 가능
	- 주로 복잡한 대화나 AI와의 다단계 상호 작용이 필요한 경우에 활용

```python
# PromptTemplate example
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate

chat = ChatOpenAI(temperature=0.1)

template = PromptTemplate.from_template(
    "What is the distance between {country_a} and {country_b}?",
)

prompt = template.format(country_a="Korea", country_b="Vietnam")

chat.predict(prompt)

# 출력
'The distance between Korea and Vietnam is approximately 2,500 kilometers (1,550 miles) when measured in a straight line.'
```
```python
# ChatPromptTemplate example
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate

chat = ChatOpenAI(temperature=0.1)

template = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a geography expert. And you only reply in {language}."),
        ("ai", "안녕! 나는 {name}이야."),
        ("human", "What is the distance between {country_a} and {country_b}? also, what is your name?"),
    ]
)

prompt = template.format_messages(
    language="Korean",
    name="chatbot",
    country_a="Korea",
    country_b="France",
)

chat.predict_messages(prompt)

# 출력
AIMessage(content='한국과 프랑스 사이의 거리는 대략 9000km입니다. 제 이름은 AI 어시스턴트입니다. 어떻게 도와드릴까요?')
```



## 3.3 OutputParser and LCEL
### 1. OutputParser
- LLM의 출력을 받아 더 적합하고 유용한 형식으로 변환하는 중요한 컴포넌트
- 구조화된 데이터 생성에 매우 유용
- LangChain 프레임워크에서 다양한 종류의 출력 데이터를 파싱하고 처리


### 2. OutputParser의 주요 특징
- 다양성: LangChain은 많은 종류의 outputParser를 제공
- 스트리밍 지원: 많은 outputParser들이 스트리밍을 지원
- 확장성: 최소한의 모듈부터 복잡한 모듈까지 확장 가능한 인터페이스를 제공


### 3. OutputParser의 장점
- 구조화: LLM의 자유 형식 텍스트 출력을 구조화된 데이터로 변환
- 일관성: 출력 형식을 일관되게 유지하여 후속 처리가 용이
- 유연성: 다양한 출력 형식(JSON, 리스트, 딕셔너리 등)으로 변환이 가능


### 4. LCEL(LangChain Expression Language)
- LangChain에서 프롬프트 템플릿을 유연하고 동적으로 구성하기 위한 표현 언어
- 템플릿 내에서 상황에 맞는 맞춤형 프롬프트를 생성 가능하게 해줌


### 5. LCEL의 주요 특징
- 동적 프롬프트 생성: 템플릿에 변수를 삽입하거나 조작 가능
- 조건문/반복문 지원: `if-else` 구문과 반복문으로 복잡한 로직 처리 가능
- 간단한 표현식 사용: 문자열 조작, 숫자 연산 등 기본 연산을 지원하여 프롬프트 논리를 확장 가능


```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import BaseOutputParser

chat = ChatOpenAI(temperature=0.1)

class CommaOutputParser(BaseOutputParser):
    # must define parse function
    def parse(self, text):
        items = text.strip().split(',')
        return list(map(str.strip, items))
        
```
```python
# without LCEL
template = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in lowercase. Do NOT reply with anything else."),
        ("human", "{question}."),
    ]
)

prompt = template.format_messages(
    max_items=10,
    question="What are the colors?"
)

result = chat.predict_messages(prompt)

p = CommaOutputParser()
p.parse(result.content)

# 출력
['red',
 'blue',
 'green',
 'yellow',
 'orange',
 'purple',
 'pink',
 'black',
 'white',
 'brown']
```
```python
# with LCEL
# make a chain of chat model, OutputParser and template.

template = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a list generating machine. Everything you are asked will be answered with a comma seperated list of max {max_items} in lowercase. Do NOT reply with anything else."),
        ("human", "{question}."),
    ]
)

chain = template | chat | CommaOutputParser()

chain.invoke({
    "max_items": 5,
    "question": "What are the pokemons?"
})

# 출력
['pikachu', 'charmander', 'bulbasaur', 'squirtle', 'jigglypuff']
```



## 3.4 Chaining Chains
### 1. Runnable
- LangChain에서 다양한 작업을 처리하고 연결하는 기본적인 구성 요소 
- 함수나 작업을 실행할 수 있는 객체를 의미
- LangChain은 다양한 작업(예: 프롬프트 템플릿 처리, API 호출, 데이터 변환 등)을 모듈화하여 관리하는데, 이런 작업들을 `Runnable`로 정의
- `Runnable`은 기본적으로 **입력을 받아서 특정 작업을 수행하고 결과를 반환**하는 역할


### 2. Runnable의 주요 특징
1) 함수형 인터페이스
	- `Runnable`은 입력을 받고 결과를 반환하는 함수형 인터페이스로 동작
	- 코드의 재사용성과 가독성을 높여줌
2) 연결과 조합
	- LangChain에서는 여러 `Runnable`들을 체인처럼 연결 가능
3) 유연성과 확장성
	- `Runnable`은 다양한 유형의 작업을 지원하기 때문에, 텍스트 변환, 데이터 필터링, 모델 호출, API 요청 등 다양한 작업을 수행 가능
	- 사용자 정의 `Runnable`을 만들 수도 있어, 특정 애플리케이션에 맞는 작업을 쉽게 확장 가능


### 3. The input type and output type varies by component
| Component    | Input Type                                            | Output Type           |
| ------------ | ----------------------------------------------------- | --------------------- |
| Prompt       | Dictionary                                            | PromptValue           |
| ChatModel    | Single string, list of chat messages or a PromptValue | ChatMessage           |
| LLM          | Single string, list of chat messages or a PromptValue | String                |
| OutputParser | The output of an LLM or ChatModel                     | Depends on the parser |
| Retriever    | Single string                                         | List of Documents     |
| Tool         | Single string or dictionary, depending on the tool    | Depends on the tool   |


### 4. Chaining Chains
```python
"""
세프에게 원하는 나라의 따라하기 쉬운 음식 레시피를 물어보고(chef_chain), 그 레시피를 채식 전문 세프에게 대체 레시피를 얻는 과정(veg_chain)
그 과정을 final_chain으로 묶어 한번에 처리
"""

from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.callbacks import StreamingStdOutCallbackHandler

# streaming: LLM의 응답이 생성되는걸 볼 수 있게 해줌
# StreamingStdOutCallbackHandler: console에서 응답의 진행을 볼 수 있음
chat = ChatOpenAI(
    temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]
)

chef_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a world-class international chef. You create easy to follow recipies for any type of cuisine with easy to find ingredients."),
    ("human", "I want to cook {cuisine} food."),
])

chef_chain = chef_prompt | chat
```
```python
veg_chef_prompt = ChatPromptTemplate.from_messages([

    ("system", "You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it."),
    ("human", "{recipe}")
])

veg_chain = veg_chef_prompt | chat
```
```python
final_chain = {"recipe": chef_chain} | veg_chain

final_chain.invoke({
    "cuisine": "indian"
})

# 출력
"""
Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Let's start with a classic and easy recipe for Chicken Tikka Masala.

Ingredients:
- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces
- 1 cup plain yogurt
- 2 tbsp lemon juice
- 2 tsp ground cumin
- 2 tsp paprika
- 1 tsp ground turmeric
- 1 tsp garam masala
- 1 tsp ground coriander
- 1/2 tsp cayenne pepper (adjust to taste)
- Salt and pepper to taste
- 2 tbsp vegetable oil
- 1 onion, finely chopped
- 3 cloves garlic, minced
- 1-inch piece of ginger, grated
- 1 can (14 oz) crushed tomatoes
- 1 cup heavy cream
- Fresh cilantro, chopped (for garnish)

Instructions:
1. In a bowl, mix together the yogurt, lemon juice, cumin, paprika, turmeric, garam masala, coriander, cayenne pepper, salt, and pepper. Add the chicken pieces and coat them well with the marinade. Cover and refrigerate for at least 1 hour, or overnight for best results.

2. Preheat the oven to 400°F (200°C). Thread the marinated chicken pieces onto skewers and place them on a baking sheet. Bake for 20-25 minutes or until the chicken is cooked through.

3. In a large skillet, heat the vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute until fragrant.

4. Stir in the crushed tomatoes and simmer for 10 minutes, stirring occasionally. Add the heavy cream and cooked chicken tikka pieces. Simmer for an additional 5-10 minutes to allow the flavors to meld together.

5. Taste and adjust seasoning if needed. Serve the Chicken Tikka Masala over steamed rice or with naan bread. Garnish with fresh cilantro before serving.

Enjoy your homemade Chicken Tikka Masala, a popular Indian dish that is sure to impress your family and friends!As a vegetarian chef, I can help you make a delicious vegetarian version of Chicken Tikka Masala by replacing the chicken with a suitable alternative. In this case, I recommend using paneer, a type of Indian cottage cheese that is commonly used in vegetarian dishes as a substitute for meat. Here's how you can prepare the paneer for this recipe:

Ingredients:
- 1 lb paneer, cut into bite-sized pieces
- 1 cup plain yogurt
- 2 tbsp lemon juice
- 2 tsp ground cumin
- 2 tsp paprika
- 1 tsp ground turmeric
- 1 tsp garam masala
- 1 tsp ground coriander
- 1/2 tsp cayenne pepper (adjust to taste)
- Salt and pepper to taste
- 2 tbsp vegetable oil
- 1 onion, finely chopped
- 3 cloves garlic, minced
- 1-inch piece of ginger, grated
- 1 can (14 oz) crushed tomatoes
- 1 cup heavy cream
- Fresh cilantro, chopped (for garnish)

Instructions:
1. In a bowl, mix together the yogurt, lemon juice, cumin, paprika, turmeric, garam masala, coriander, cayenne pepper, salt, and pepper. Add the paneer pieces and coat them well with the marinade. Cover and refrigerate for at least 1 hour, or overnight for best results.

2. Preheat the oven to 400°F (200°C). Thread the marinated paneer pieces onto skewers and place them on a baking sheet. Bake for 20-25 minutes or until the paneer is slightly browned.

3. In a large skillet, heat the vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the garlic and ginger, and cook for another minute until fragrant.

4. Stir in the crushed tomatoes and simmer for 10 minutes, stirring occasionally. Add the heavy cream and cooked paneer tikka pieces. Simmer for an additional 5-10 minutes to allow the flavors to meld together.

5. Taste and adjust seasoning if needed. Serve the Paneer Tikka Masala over steamed rice or with naan bread. Garnish with fresh cilantro before serving.

Enjoy your vegetarian version of Chicken Tikka Masala made with paneer, a flavorful and satisfying alternative to chicken!
"""
```